{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamyaMangu/RamyaMangu/blob/main/Bioannotator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afX0DD989pMF"
      },
      "source": [
        "**LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "eF52QQXz9tW3"
      },
      "outputs": [],
      "source": [
        "import urllib.request, urllib.error, urllib.parse\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "import string\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as pyo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0KCl-w9yuY"
      },
      "source": [
        "**DATA IMPORT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAeU0FSr93ep",
        "outputId": "aca49f84-a432-42a9-ad49-6e86461284ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/ASR transcribed data\n",
            "/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/Original conversation Data/cleaned for asr eval/cleaned csv reader scripts for asr eval\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/ASR transcribed data\n",
        "dirName_a1 = '/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/ASR transcribed data/Amazon Transcribe Medical - 2022-03-03/CSV for Evaluation'\n",
        "data_files_a1 = list() #medical amazon folder\n",
        "for root, dirs, files in os.walk(dirName_a1):\n",
        "    for file in files:\n",
        "            data_files_a1 += [os.path.join(dirName_a1, file)]\n",
        "\n",
        "dirName_a2 = '/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/ASR transcribed data/Amazon Transcribe General - 2022-03-03/CSV for Evaluation'\n",
        "data_files_a2 = list() #general amazon folder\n",
        "for root, dirs, files in os.walk(dirName_a2):\n",
        "    for file in files:\n",
        "            data_files_a2 += [os.path.join(dirName_a2, file)]\n",
        "\n",
        "dirName_g1 = '/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/ASR transcribed data/Google Speech to Text medical_conversations - 2022-03-03/CSV for evaluation'\n",
        "data_files_g1 = list() #medical amazon folder\n",
        "for root, dirs, files in os.walk(dirName_g1):\n",
        "    for file in files:\n",
        "            data_files_g1 += [os.path.join(dirName_g1, file)]\n",
        "\n",
        "dirName_g2 = '/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/ASR transcribed data/Google Speech to Text Video - 2022-03-03/CSV for Evaluation'\n",
        "data_files_g2 = list() #medical amazon folder\n",
        "for root, dirs, files in os.walk(dirName_g2):\n",
        "    for file in files:\n",
        "            data_files_g2 += [os.path.join(dirName_g2, file)]\n",
        "#So now we have the list of files for each engine\n",
        "\n",
        "# Now for the reference directory\n",
        "%cd /content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/Original conversation Data/cleaned for asr eval/cleaned csv reader scripts for asr eval\n",
        "dirName_ref = '/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/Original conversation Data/cleaned for asr eval/cleaned csv reader scripts for asr eval'\n",
        "datafiles_ref = list()\n",
        "for root, dirs, files in os.walk(dirName_ref):\n",
        "    for file in files:\n",
        "            datafiles_ref += [os.path.join(dirName_ref, file)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3GD7wkdDAmH"
      },
      "source": [
        "**Removing punctuations and Converting each file into string of words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3dhB5tWADDTb"
      },
      "outputs": [],
      "source": [
        "def convert(data_f, dict_df):\n",
        "  length = len(data_f)\n",
        "  for i in range(length):\n",
        "    tf = pd.read_csv(data_f[i])\n",
        "    string_trans = ' '.join(tf['ASR Text'].to_list())\n",
        "    translator=str.maketrans('','',string.punctuation) #translator to remove the punctuations\n",
        "    string_trans=string_trans.translate(translator)\n",
        "    id = tf['Hyp Visit ID'].iloc[0]\n",
        "    dict_df[id] = string_trans\n",
        "\n",
        "def ref_convert(data_f, dict_df):\n",
        "  for i in range(len(data_f)):\n",
        "    tf = pd.read_csv(data_f[i])\n",
        "    string_trans = ' '.join(tf['Ref Word'].to_list())\n",
        "    id = tf['Ref Visit ID'].iloc[0]\n",
        "    dict_df[id] = string_trans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wJilit5oIxsv"
      },
      "outputs": [],
      "source": [
        "a1 = {}\n",
        "convert(data_files_a1, a1)\n",
        "a2 = {}\n",
        "convert(data_files_a2, a2)\n",
        "g1 = {}\n",
        "convert(data_files_g1, g1)\n",
        "g2 = {}\n",
        "convert(data_files_g2, g2)\n",
        "#so now a1, a2, g1 aand g2 are our dictionaries that have the visit id's as keys and strings of words as values from each transcipt without punctuations.\n",
        "ref = {}\n",
        "ref_convert(datafiles_ref, ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGB6FK_5JNsQ"
      },
      "source": [
        "**Bioannotator API import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gDeH-WwqJOE_"
      },
      "outputs": [],
      "source": [
        "# getting our bioannotator json file\n",
        "REST_URL = \"http://data.bioontology.org\"\n",
        "API_KEY = \"\"\n",
        "\n",
        "\n",
        "def get_json(url):\n",
        "    opener = urllib.request.build_opener()\n",
        "    opener.addheaders = [('Authorization', 'apikey token=' + API_KEY)]\n",
        "    return json.loads(opener.open(url).read())\n",
        "\n",
        "\n",
        "def print_annotations(annotations, get_class=True):\n",
        "    for result in annotations:\n",
        "        class_details = result[\"annotatedClass\"]\n",
        "        if get_class:\n",
        "            try:\n",
        "                class_details = get_json(result[\"annotatedClass\"][\"links\"][\"self\"])\n",
        "            except urllib.error.HTTPError:\n",
        "                print(f\"Error retrieving {result['annotatedClass']['@id']}\")\n",
        "                continue\n",
        "        print(\"Class details\")\n",
        "        print(\"\\tid: \" + class_details[\"@id\"])\n",
        "        print(\"\\tprefLabel: \" + class_details[\"prefLabel\"])\n",
        "        print(\"\\tontology: \" + class_details[\"links\"][\"ontology\"])\n",
        "\n",
        "        print(\"Annotation details\")\n",
        "        for annotation in result[\"annotations\"]:\n",
        "            print(\"\\tfrom: \" + str(annotation[\"from\"]))\n",
        "            print(\"\\tto: \" + str(annotation[\"to\"]))\n",
        "            print(\"\\tmatch type: \" + annotation[\"matchType\"])\n",
        "\n",
        "        if result[\"hierarchy\"]:\n",
        "            print(\"\\n\\tHierarchy annotations\")\n",
        "            for annotation in result[\"hierarchy\"]:\n",
        "                try:\n",
        "                    class_details = get_json(annotation[\"annotatedClass\"][\"links\"][\"self\"])\n",
        "                except urllib.error.HTTPError:\n",
        "                    print(f\"Error retrieving {annotation['annotatedClass']['@id']}\")\n",
        "                    continue\n",
        "                pref_label = class_details[\"prefLabel\"] or \"no label\"\n",
        "                print(\"\\t\\tClass details\")\n",
        "                print(\"\\t\\t\\tid: \" + class_details[\"@id\"])\n",
        "                print(\"\\t\\t\\tprefLabel: \" + class_details[\"prefLabel\"])\n",
        "                print(\"\\t\\t\\tontology: \" + class_details[\"links\"][\"ontology\"])\n",
        "                print(\"\\t\\t\\tdistance from originally annotated class: \" + str(annotation[\"distance\"]))\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRRfEuDJY6Q"
      },
      "source": [
        "**Chunking the files and sending it to the bioannotator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zu7O-hFbJg9Z"
      },
      "outputs": [],
      "source": [
        "def chunk(lis, an, an2):\n",
        "  length_lis = len(lis)\n",
        "  l =0\n",
        "  for key, value in lis.items(): # iterating through the dictionary\n",
        "    ind_len = divmod(len(value), 15) #splitting the string into 15 parts\n",
        "    j = 0\n",
        "    string_ch = \"\"\n",
        "    str_ch =[]\n",
        "    for h in value:\n",
        "      string_ch += h\n",
        "      if j == ind_len[0]:\n",
        "        str_ch.append(string_ch)\n",
        "        string_ch =\"\"\n",
        "        j = 0\n",
        "      else:\n",
        "        j= j +1\n",
        "    an[key] = {} # creating a dictionary for each visit id that holds the annotation ids as keys and its occurences as values like [visitId][annId][no.of occurences]\n",
        "    an2[key] = list() # this will used for the json file\n",
        "    for k in range(len(str_ch)):\n",
        "      annotations = get_json(REST_URL + \"/annotator?text=\" + urllib.parse.quote(str_ch[k]))\n",
        "      an2[key].extend(annotations) # adding the complete annotations to the dictionary\n",
        "      for l in range(len(annotations)):\n",
        "        val = annotations[l]['annotatedClass']['@id']\n",
        "        if val in an[key]:\n",
        "          an[key][val]+=1\n",
        "        else:\n",
        "          an[key][val]= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3E1M1qF0R1AG"
      },
      "outputs": [],
      "source": [
        "#chunking all the files and sending it to the bioannotator\n",
        "anid_ama_med ={}\n",
        "an_amed = {}\n",
        "anid_ama_gen ={}\n",
        "an_agen = {}\n",
        "anid_gog_med={}\n",
        "an_gmed = {}\n",
        "anid_gog_gen={} \n",
        "an_ggen = {}\n",
        "anid_ref={}\n",
        "an_ref = {}\n",
        "chunk(a1, anid_ama_med, an_amed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk(a2, anid_ama_gen, an_agen)"
      ],
      "metadata": {
        "id": "m7pRAIBSSUWV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dCcC8v5kx0de"
      },
      "outputs": [],
      "source": [
        "chunk(g1, anid_gog_med, an_gmed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LIB5AYe4x2RX"
      },
      "outputs": [],
      "source": [
        "chunk(g2, anid_gog_gen, an_ggen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q4hm0u0N79qK"
      },
      "outputs": [],
      "source": [
        "chunk(ref, anid_ref, an_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0FU2ey4ka_Lt"
      },
      "outputs": [],
      "source": [
        "anids = {\"Amazon Transcribe Medical\":anid_ama_med, \n",
        "         \"Amazon Transcribe General\":anid_ama_gen, \n",
        "         \"Google Speech-to-Text Medical_Conversations\":anid_gog_med, \n",
        "         \"Google Speech-to-Text Video\":anid_gog_gen}\n",
        "ans = {\"Amazon Transcribe Medical\":[an_amed, a1], \n",
        "         \"Amazon Transcribe General\":[an_agen, a2], \n",
        "         \"Google Speech-to-Text Medical_Conversations\":[an_gmed, g1], \n",
        "         \"Google Speech-to-Text Video\":[an_ggen, g2]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-RJpqDeUVJD"
      },
      "source": [
        "**Calculating Precision and Recall**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3Al5GzO0UZI0"
      },
      "outputs": [],
      "source": [
        "# We calculate the true positives, false positives and false negatives through the below function and then calculate the precision and recall manually\n",
        "#true positive is when the annotation label is there in both reference and the transcribed file\n",
        "#false negative is when the annotation label is there in reference but not in the transcribed file\n",
        "#false positive is when the annotation label is there in the transcibed files but not in the reference\n",
        "def calculate_tp_fn(ref, trans):\n",
        "  tp =0\n",
        "  fn =0\n",
        "  for key in ref:\n",
        "    if key in trans:\n",
        "      tp+= 1\n",
        "    fn+=1\n",
        "  return(tp,fn)\n",
        "\n",
        "def calculate_fp(ref, trans):\n",
        "  fp = 0\n",
        "  for key in trans:\n",
        "    if key not in ref:\n",
        "      fp+=1\n",
        "  return fp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_rMq5fJcaAu"
      },
      "source": [
        "**Creating an output table for each Visit ID**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Vn4p_3aWb4HN"
      },
      "outputs": [],
      "source": [
        "columns= [\n",
        "          'Visit ID', 'Engine', 'True Positive', 'False Positive', 'Precision', 'Recall', 'F1 Score' \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6i68zEGUepqc"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/Bioannotator_Analysis_ASR_transcribed data/CSV\"\n",
        "def create_output(ref, dict_ids, values, vi_metrics):\n",
        "  for key, value in ref.items():\n",
        "    data = pd.DataFrame(columns=columns)\n",
        "    vi_metrics[key] = {} # dict for each visit id\n",
        "    # iterating through all the four folders\n",
        "    for k,val in dict_ids.items():\n",
        "      ids = val[key] #taking the values of that particular id\n",
        "      tp, fn = calculate_tp_fn(value, ids)\n",
        "      # we will storing the values with their respective engine names like so [engine type]{tp, fp, fn, recall...} and we will be updating the values accordingly\n",
        "      if k not in values:\n",
        "        values[k] ={}\n",
        "        values[k]['tp'] =0\n",
        "        values[k]['fp'] =0 \n",
        "        values[k]['fn'] =0 \n",
        "        values[k]['recall'] =0 \n",
        "        values[k]['precision'] =0 \n",
        "        values[k]['f1'] =0 \n",
        "      values[k]['tp'] += tp\n",
        "      values[k]['fn'] += fn\n",
        "      recall = tp/(tp+fn)\n",
        "      values[k]['recall'] += recall\n",
        "      fp = calculate_fp(value, ids)\n",
        "      values[k]['fp'] += fp\n",
        "      precision = tp/(tp+fp)\n",
        "      values[k]['precision'] += precision\n",
        "      f1_score = (2 * precision * recall)/(precision + recall)\n",
        "      values[k]['f1'] += f1_score\n",
        "      vi_metrics[key][k] = list()\n",
        "      vi_metrics[key][k].extend([tp])\n",
        "      vi_metrics[key][k].extend([fn])\n",
        "      vi_metrics[key][k].extend([fp])\n",
        "      vi_metrics[key][k].extend([recall])\n",
        "      vi_metrics[key][k].extend([precision])\n",
        "      vi_metrics[key][k].extend([f1_score])\n",
        "      #data.loc[len(data.index)]= [key,k,tp,fp,round(precision, 2),round(recall,2),round(f1_score, 2)]\n",
        "     #filePathNameWExt =  path + '/' + str(key) + '_Bioannotator_anlaysis' + '.csv'\n",
        "   # data.to_csv(filePathNameWExt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ls7G3oikYg_K"
      },
      "outputs": [],
      "source": [
        "values = {} # this will be storing the sum of the values of the tps, fps, fns, recall, precision to help us compute the macro and micro average later.\n",
        "vi_metrics = {} # dict that stores the fp, tp, fn, recall and precision by visit ID. In the order tp, fp, fn, recall and f1 score - format [visitId][Engine] = [tp, fn, fp, recall, prec]\n",
        "create_output(anid_ref, anids, values, vi_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4LA9wXD8o-D"
      },
      "source": [
        "**Create a JSON file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1qkLAUW8sPx"
      },
      "outputs": [],
      "source": [
        "def create_json(path, annot):\n",
        "  for result in annot:\n",
        "    class_details = result[\"annotatedClass\"]\n",
        "    class_details = get_json(result[\"annotatedClass\"][\"links\"][\"self\"])\n",
        "    newdat = {\n",
        "      'Class Details' : [\n",
        "                         {\n",
        "                             'id:' : class_details[\"@id\"],\n",
        "                             'prefLabel:' : class_details[\"prefLabel\"],\n",
        "                             'ontology:' : class_details[\"links\"][\"ontology\"]\n",
        "                         }\n",
        "      ]\n",
        "   }\n",
        "    path.append(newdat)\n",
        "    for annotation in result[\"annotations\"]:\n",
        "      annotdat={\n",
        "          'Annotation Details' : [{\n",
        "              \"from: \" : str(annotation[\"from\"]),\n",
        "              \"to: \" : str(annotation[\"to\"]),\n",
        "              \"match type: \" : annotation[\"matchType\"]\n",
        "          }]\n",
        "    }\n",
        "      path.append(annotdat)\n",
        "    #j_string = json.dumps(newdat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS4fq0rCLmai"
      },
      "outputs": [],
      "source": [
        "ppath = \"/content/drive/Shareddrives/ASR Recording Modality Errors Analysis/Data/Bioannotator_Analysis_ASR_transcribed data/JSON\"\n",
        "for key, value in an_ref.items():\n",
        "  direc = str(key)\n",
        "  path = os.path.join(ppath, direc)\n",
        "  if not os.path.isdir(path):\n",
        "    os.makedirs(path)\n",
        "  dat = [{\n",
        "      'Reference' : [{'Visit Id': int(key)}, {'String' :ref[int(key)]}]\n",
        "      \n",
        "  }]\n",
        "  filejson = path + '/' + str(key) + '_Reference_Bioannotator_anlaysis' + '.json'\n",
        "  #j_string = json.dumps(dat)\n",
        "  create_json(dat, value)\n",
        "  with open(filejson, 'w') as j_file:\n",
        "      json.dump(dat, j_file)\n",
        "  for k, v1 in ans.items():\n",
        "    filejson = path + '/' + str(key) + '_'+ k +'_Bioannotator_anlaysis' + '.json'\n",
        "    newdat = [{\n",
        "      k : {'Visit Id': int(key)},\n",
        "      'Sent in string' : v1[1][key]\n",
        "    }]\n",
        "    create_json(newdat, v1[0][key])\n",
        "    with open(filejson, 'w') as j_file:\n",
        "      json.dump(newdat, j_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Y8fcEDyj0n"
      },
      "source": [
        "**Creating The Output Table**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_NVfvvgZxeMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893ed8b0-6806-4de2-d9c2-dde9e5a9f552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════════════════════════════════════════════╤════════════════════════╤════════════════════════╤═══════════════════════════╤═══════════════════════════╤════════════════════╤════════════════════╕\n",
            "│ Engine Type                                 │   Recall Macro Average │   Recall Micro Average │   Precision Macro Average │   Precision Micro Average │   F1 Macro Average │   F1 Micro Average │\n",
            "╞═════════════════════════════════════════════╪════════════════════════╪════════════════════════╪═══════════════════════════╪═══════════════════════════╪════════════════════╪════════════════════╡\n",
            "│ Amazon Transcribe Medical                   │               0.479348 │               0.479991 │                  0.945213 │                  0.943825 │           0.636024 │           0.636357 │\n",
            "├─────────────────────────────────────────────┼────────────────────────┼────────────────────────┼───────────────────────────┼───────────────────────────┼────────────────────┼────────────────────┤\n",
            "│ Amazon Transcribe General                   │               0.486804 │               0.487186 │                  0.963372 │                  0.963619 │           0.646753 │           0.647174 │\n",
            "├─────────────────────────────────────────────┼────────────────────────┼────────────────────────┼───────────────────────────┼───────────────────────────┼────────────────────┼────────────────────┤\n",
            "│ Google Speech-to-Text Medical_Conversations │               0.487359 │               0.487417 │                  0.94725  │                  0.947181 │           0.643532 │           0.643625 │\n",
            "├─────────────────────────────────────────────┼────────────────────────┼────────────────────────┼───────────────────────────┼───────────────────────────┼────────────────────┼────────────────────┤\n",
            "│ Google Speech-to-Text Video                 │               0.488261 │               0.488595 │                  0.959486 │                  0.960112 │           0.647153 │           0.64762  │\n",
            "╘═════════════════════════════════════════════╧════════════════════════╧════════════════════════╧═══════════════════════════╧═══════════════════════════╧════════════════════╧════════════════════╛\n"
          ]
        }
      ],
      "source": [
        "head = [\"Engine Type\", \"Recall Macro Average\", \"Recall Micro Average\", \"Precision Macro Average\", \"Precision Micro Average\", \"F1 Macro Average\", \"F1 Micro Average\"]\n",
        "data = list()\n",
        "for k, val in values.items():\n",
        "  micRec = val['tp'] / (val['tp'] + val['fn'])\n",
        "  micPrec = val['tp'] / (val['tp'] + val['fp'])\n",
        "  micf1 = (2 * micRec * micPrec)/(micPrec+micRec)\n",
        "  macf1 = val['f1']/len(ref)\n",
        "  macrec = val['recall']/len(ref)\n",
        "  macprec = val['precision']/len(ref)\n",
        "  ls = [k, macrec, micRec, macprec, micPrec, macf1, micf1]\n",
        "  data.append(ls)\n",
        "\n",
        "print(tabulate(data, headers=head, tablefmt='fancy_grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8tojxB0VLuf"
      },
      "source": [
        "**Analysis of Analysis** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhIx1X9OWoV6"
      },
      "source": [
        "- **Bar graphs for tp, fp and fn for each visit id**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "oKK-H6ASWrlm"
      },
      "outputs": [],
      "source": [
        "def plot(labels, metric, dict_eng):\n",
        "  x = np.arange(40)\n",
        "  lab = []\n",
        "  for k, val in dict_eng.items():\n",
        "    lab.append(k)\n",
        "  width = 0.3\n",
        "  plt.figure(figsize=(40, 10))\n",
        "  plt.bar(x-0.6, dict_eng[lab[0]], width, color='cyan')\n",
        "  plt.bar(x-0.3, dict_eng[lab[1]], width, color='orange')\n",
        "  plt.bar(x, dict_eng[lab[2]], width, color='green')\n",
        "  plt.bar(x+0.3, dict_eng[lab[3]], width, color='blue')\n",
        "  plt.xticks(x, labels)\n",
        "  plt.xlabel(\"Visit Ids\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend(lab)\n",
        "  \n",
        "def bar_graph(dict_vi):\n",
        "  lab = ['tp', 'fp', 'fn', 'recall', 'precision', 'f1 score']\n",
        "  for i in range(0, 7):\n",
        "    labels = [] # This will store the visit ids\n",
        "    eng_metri = dict()\n",
        "    for key, value in dict_vi.items():\n",
        "      labels.append(key)\n",
        "      for val in value:\n",
        "        eng_metri[val] = list()\n",
        "        eng_metri[val].extend([value[val][i]])\n",
        "    \n",
        "    plot(labels, lab[i], eng_metri)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSiYgmylbkoO"
      },
      "source": [
        "- **Radar graph based on each engine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "5i1rQsFMbslf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "99315654-cbad-4856-d39b-04f57f67c26e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8055cc32-5c6f-4d29-b326-09305d382887\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8055cc32-5c6f-4d29-b326-09305d382887\")) {                    Plotly.newPlot(                        \"8055cc32-5c6f-4d29-b326-09305d382887\",                        [{\"name\":\"Recall\",\"r\":[0.47934839165042065,0.48680412893775604,0.4873593385297819,0.4882614129360106],\"theta\":[\"Amazon Transcribe Medical\",\"Amazon Transcribe General\",\"Google Speech-to-Text Medical_Conversations\",\"Google Speech-to-Text Video\"],\"type\":\"scatterpolar\"},{\"name\":\"Precision\",\"r\":[0.9452127519332948,0.9633720562065063,0.9472501893484644,0.959486198672329],\"theta\":[\"Amazon Transcribe Medical\",\"Amazon Transcribe General\",\"Google Speech-to-Text Medical_Conversations\",\"Google Speech-to-Text Video\"],\"type\":\"scatterpolar\"},{\"name\":\"F1 Score\",\"r\":[0.6360237397787478,0.6467531214199929,0.6435324705492345,0.6471526225835466],\"theta\":[\"Amazon Transcribe Medical\",\"Amazon Transcribe General\",\"Google Speech-to-Text Medical_Conversations\",\"Google Speech-to-Text Video\"],\"type\":\"scatterpolar\"}],                        {\"polar\":{\"radialaxis\":{\"visible\":true}},\"showlegend\":true,\"title\":{\"text\":\"Performance\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8055cc32-5c6f-4d29-b326-09305d382887');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "categories = [\"Amazon Transcribe Medical\", \"Amazon Transcribe General\", \"Google Speech-to-Text Medical_Conversations\", \"Google Speech-to-Text Video\"]\n",
        "recall =[]\n",
        "precision =[]\n",
        "f1 =[]\n",
        "for k, val in values.items():\n",
        "  macf1 = val['f1']/len(ref)\n",
        "  macrec = val['recall']/len(ref)\n",
        "  macprec = val['precision']/len(ref)\n",
        "  recall.append(macrec)\n",
        "  precision.append(macprec)\n",
        "  f1.append(macf1)\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatterpolar(r=recall, theta=categories, name='Recall'),\n",
        "        go.Scatterpolar(r=precision, theta=categories, name='Precision'),\n",
        "        go.Scatterpolar(r=f1, theta=categories, name='F1 Score')\n",
        "    ],\n",
        "    layout=go.Layout(\n",
        "        title=go.layout.Title(text='Performance'),\n",
        "        polar={'radialaxis': {'visible': True}},\n",
        "        showlegend=True\n",
        "    )\n",
        ")\n",
        "\n",
        "pyo.plot(fig)\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Bioannotator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgtmkhfjFRs3Zkyy7modQs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}